---
title: 图片存储方案  
date: 2022-08-31 12:57:34  
permalink: /pages/delicate/image_store/  
categories:
  - 前端
  - 知识体系
  - 精华
tags:
  - 精华
author:  
  name: WJYGRIT   
  link: https://github.com/GRITWJY
---

# 01.图片存储方案

## 简述

由于我自己项目中本来就有 **大量图片** 存储的情况，现在是存储在阿里云的 `OSS` 中的。 每学期可以达到`80G， 两万多张`。

但当时并没有怎么系统的了解图片存储， 再网上找了一些资料后发现, 有很多涉及到我的知识盲区了， 有必要拓展下了。


> **重点：** 我的需求是学生上传报告，老师批改报告。 
> 
> - 上传报告可能会出现 一个时间段内大量上传的情况
> - 批改报告也会有 并发的问题。
> - 每学期的报告数量在2W+
> - 由于要批改，报告最终的大小在 0.5 M左右

## 常见的存储方案

- **1. 存储服务器上的文件夹下。**
  这个方案就不多说了， 只适用于个人博客等小用户量的情况
  
- **2. 把图片以二进制存在数据库中**
  - 使用场景：小项目，图片数据量没有那么多。不用考虑数据量的情况下。
  - 好处：方便操作。
  - 弊端：这是依赖数据库的，一般来说图片都是要占用比较大的存储空间的。这会给数据库带来很大的负担。不信你去找你们公司的DBA商量一下这个事情，看DBA是不是会拿板凳砸你。并且这种方式太不主流了，我是基本上没有见过有这样用的。

- **3.使用nginx搭建一个文件存储服务器。** 这样图片就可以作为url路径的方式给前端用于展示。
  - 适用场景：这种方式比较常见的，中小型企业都可以适用的方案。它的性能依赖于nginx。nginx本身的出色性能，让这种方案变得可行。
  - 好处：借用了nginx的性能。将图片作为静态资源来访问。并且可以给nginx配置独立的域名，可以做到静态资源分离，这样不会和业务抢占资源。
  - 弊端：也不能说是弊端吧，主要是我们要考虑一些问题，比方说，我们在服务器下，特定配置下，单个目录下放多少个图片合适。还需要考虑图片增长问题，到达一定级别，我们应该如何去扩展。这可能我们需要使用一些代码，编写一些算法来完成。
  - 注意事项：我们要注意图片的命名规则，要主要唯一性。比如网站的并发访问量大，目录的生成分得月细越好。比如精确到小时，一个小时都可以是一个文件夹。同时0.001秒有两个用户同时在上传图片(因为那么就会往同一个小时文件夹里面存图片)。因为时间戳是精确到秒的。为了做到图片名称唯一性而不至于覆盖，生成可以在在时间戳后面继续加毫秒微秒等。总结的规律是，并发访问量越大。就越精确就好了。

- **4.使用 nginx + FTP，共享文件目录的方式。**
  - 适用场景：这种方式相当于是上边第二种方式的升级。
  - 好处：解决了扩展性的问题。 将图片服务和应用服务分离，缓解应用服务器的I/O负载。通过共享目录的方式来进行读写操作，可以避免多服务器之间同步相关的问题。 相对来讲很灵活，也支持扩容/扩展。支持配置成独立图片服务器和域名访问，方便日后的扩展和优化。相对于更加复杂的分布式的NFS 系统，这种方式是性价比高，符合目前互联网的“短平快”的开发模式。
  - 弊端：共享目录配置有些繁琐， 会造成一定的（读写和安全）性能损失。如果图片服务器出现问题，那所有的应用都会受到影响。同时也对存储服务器的性能要求特别高。图片上传操作，还是得经过Web服务器，这对Web服务器还是有巨大的压力。


- **5. 云服务的对象存储**
  - 好处就是自己不用去维护
  - 弊端： 费用较高。


## [扩展-典型Web应用中大量图片的服务端存储加构的演进过程](https://blog.csdn.net/weixin_33721427/article/details/89663072?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-89663072-blog-52535676.pc_relevant_multi_platform_whitelistv4&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-89663072-blog-52535676.pc_relevant_multi_platform_whitelistv4&utm_relevant_index=2)


### 单机时代的图片服务器架构（集中式）
初创时期由于时间紧迫，开发人员水平很有限。

**所以通常就直接在website文件所在的目录下，建立1个upload子目录，用于保存用户上传的图片文件：**

这个就与上面的第一个方法一样， **主要面临如下问题**

随着upload目录中文件越来越多，所在分区如果出现容量不足，则很难扩容。只能停机后更换更大容量的存储设备，再将旧数据导入；

在部署新版本（部署新版本前通过需要备份）和日常备份website文件的时候，需要同时操作upload目录中的文件，如果考虑到访问量上升，后边部署由多台Web服务器组成的负载均衡集群，集群节点之间如果做好文件实时同步将是个难题。


### 集群时代的图片服务器架构（实时同步）

一个传统的Web服务端站点下面，新建一个名为upload的虚拟目录，由于虚拟目录的灵活性，能在一定程度上取代物理目录，并兼容原有的图片上传和访问方式

**优点**：配置更加灵活，也能兼容老版本的上传和访问方式。因为虚拟目录，可以指向本地任意盘符下的任意目录。这样一来，还可以通过接入外置存储，来进行单机的容量扩展。

**缺点**：部署成由多台Web服务器组成的集群，各个Web服务器（集群节点）之间（虚拟目录下的）需要实时的去同步文件，由于同步效率和实时性的限制，很难保证某一时刻各节点上文件是完全一致的。
<img :src = "$withBase( '/30fn0dn/img.png' )" alt = "foo" />
从上图可看出，整个Web服务器架构已经具备“可扩展、高可用”了，主要问题和瓶颈都集中在多台服务器之间的文件同步上。

上述架构中只能在这几台Web服务器上互相“增量同步”，这样一来，就不支持文件的“删除、更新”操作的同步了。

早期的想法是，在应用程序层面做控制，当用户请求在web1服务器进行上传写入的同时，也同步去调用其它web服务器上的上传接口，这显然是得不偿失的。所以我们选择使用Rsync类的软件来做定时文件同步的，从而省去了“重复造轮子”的成本，也降低了风险性。

同步操作里面，一般有比较经典的两种模型，即推拉模型：所谓“拉”，就是指轮询地去获取更新，所谓推，就是发生更改后主动的“推”给其它机器。当然，也可以采用加高级的事件通知机制来完成此类动作。

在高并发写入的场景中，同步都会出现效率和实时性问题，而且大量文件同步也是很消耗系统和带宽资源的（跨网段则更明显）。

### 集群时代的图片服务器架构改进（共享存储）


沿用虚拟目录的方式，通过UNC（网络路径）的方式实现共享存储（将upload虚拟目录指向UNC）。

**用户的访问方式1：** `http://www.yourdomain.com/upload/qa/test.jpg`

**用户的访问方式2（可以配置独立域名）：** `http://img.yourdomain.com/upload/qa/test.jpg`

支持UNC所在server上配置独立域名指向，并配置轻量级的web服务器，来实现独立图片服务器。

**优点**： 通过UNC（网络路径）的方式来进行读写操作，可以避免多服务器之间同步相关的问题。相对来讲很灵活，也支持扩容/扩展。支持配置成独立图片服务器和域名访问，也完整兼容旧版本的访问规则。

**缺点**：但是UNC配置有些繁琐，而且会造成一定的（读写和安全）性能损失。可能会出现“单点故障”。如果存储级别没有raid或者更高级的灾备措施，还会造成数据丢失。
<img :src = "$withBase( '/30fn0dn/img_1.png' )" alt = "foo" />

在早期的很多基于Linux开源架构的网站中，如果不想同步图片，可能会利用NFS来实现。事实证明，NFS在高并发读写和海量存储方面，效率上存在一定问题，并非最佳的选择，所以大部分互联网公司都不会使用NFS来实现此类应用。当然，也可以通过Windows自带的DFS来实现，缺点是“配置复杂，效率未知，而且缺乏资料大量的实际案例”。另外，也有一些公司采用FTP或Samba来实现。

上面提到的几种架构，在上传/下载操作时，都经过了Web服务器（虽然共享存储的这种架构，也可以配置独立域名和站点来提供图片访问，但上传写入仍然得经过Web服务器上的应用程序来处理），这对Web服务器来讲无疑是造成巨大的压力。所以，更建议使用独立的图片服务器和独立的域名，来提供用户图片的上传和访问。


### 独立图片服务器/独立域名的好处

图片访问是很消耗服务器资源的（因为会涉及到操作系统的上下文切换和磁盘I/O操作）。分离出来后，Web/App服务器可以更专注发挥动态处理的能力。

- 独立存储，更方便做扩容、容灾和数据迁移；
- 浏览器（相同域名下的）并发策略限制，性能损失；
- 访问图片时，请求信息中总带cookie信息，也会造成性能损失；
- 方便做图片访问请求的负载均衡，方便应用各种缓存策略（HTTP Header、Proxy Cache等），也更加方便迁移到CDN；
- ......

我们可以使用Lighttpd或者Nginx等轻量级的web服务器来架构独立图片服务器


### 我们当前的图片服务器架构

当前图片服务器架构采用分布式文件系统+CDN。

在构建当前的图片服务器架构之前，可以先彻底撇开web服务器，直接配置单独的图片服务器/域名。

**但面临如下的问题：**

- 旧图片数据怎么办？能否继续兼容旧图片路径访问规则？
- 独立的图片服务器上需要提供单独的上传写入的接口（服务API对外发布），安全问题如何保证？
- 同理，假如有多台独立图片服务器，是使用可扩展的共享存储方案，还是采用实时同步机制？

直到应用级别的（非系统级） DFS（例如FastDFS HDFS MogileFs MooseFS、TFS）的流行，简化了这个问题：执行冗余备份、支持自动同步、支持线性扩展、支持主流语言的客户端api上传/下载/删除等操作，部分支持文件索引，部分支持提供Web的方式来访问。

考虑到各DFS的特点，客户端API语言支持情况(需要支持C#)，文档和案例，以及社区的支持度，我们最终选择了FastDFS来部署。

**唯一的问题是**：可能会不兼容旧版本的访问规则。如果将旧图片一次性导入FastDFS，但由于旧图片访问路径分布存储在不同业务数据库的各个表中，整体更新起来也十分困难，所以必须得兼容旧版本的访问规则。架构升级往往比做全新架构更有难度，就是因为还要兼容之前版本的问题。（给飞机在空中换引擎可比造架飞机难得多）

**解决方案如下：**

首先，关闭旧版本上传入口（避免继续使用导致数据不一致）。将旧图片数据通过rsync工具一次性迁移到独立的图片服务器上（即下图中描述的Old Image Server）。在最前端(七层代理，如Haproxy、Nginx)用ACL（访问规则控制），将旧图片对应URL规则的请求（正则）匹配到，然后将请求直接转发指定的web 服务器列表，在该列表中的服务器上配置好提供图片（以Web方式）访问的站点，并加入缓存策略。这样实现旧图片服务器的分离和缓存,兼容了旧图片的访问规则并提升旧图片访问效率，也避免了实时同步所带来的问题。
<img :src = "$withBase( '/30fn0dn/img_2.png' )" alt = "foo" />


## 总结，

有关图片服务器架构扩展，大致围绕这些问题展开：

- 容量规划和扩展问题；
- 数据的同步、冗余和容灾；
- 硬件设备的成本和可靠性（是普通机械硬盘，还是SSD，或者更高端的存储设备和方案）；
- 文件系统的选择。根据文件特性（例如文件大小、读写比例等）选择是用ext3/4或者NFS/GFS/TFS这些开源的（分布式）文件系统；
- 图片的加速访问。采用商用CDN或者自建的代理缓存、web静态缓存架构；
- 旧图片路径和访问规则的兼容性，应用程序层面的可扩展，上传和访问的性能和安全性等。
